# AI News Digest Bot

Этот проект представляет собой автоматизированную систему для сбора, анализа и публикации еженедельного дайджеста новостей. Архитектура проекта позволяет запускать несколько независимых ботов из одной кодовой базы, каждый со своей конфигурацией, тематикой и базой данных.

## Архитектура

Приложение построено на двухэтапной архитектуре **"Сначала фильтруем, потом синтезируем"** для обеспечения высокой надежности и качества контента при обработке больших объемов данных.

1.  **Этап 1: Фильтрация и предварительная обработка (`SUMMARY_PROMPT`)**
    *   **`telegram_parser.py`**: Собирает посты из Telegram-каналов, указанных в конфигурации.
    *   **`database.py`**: Хранит собранные посты в **SQLite**.
    *   **`main.py` (цикл пакетной обработки)**: Посты обрабатываются небольшими пачками. Для каждой пачки вызывается **OpenAI API** с промптом `SUMMARY_PROMPT`, задача которого — отфильтровать информационный шум (рекламу, мемы, повторы) и вернуть только самые важные посты в их первозданном виде.

2.  **Этап 2: Синтез и публикация (`ARTICLE_PROMPT`)**
    *   **`main.py` (финальный вызов)**: Все отфильтрованные посты объединяются и передаются в **OpenAI API** с основным промптом `ARTICLE_PROMPT`.
    *   **`article_generator.py`**: На основе этого промпта генерируется полноценный, структурированный лонгрид в HTML и краткое саммари для анонса.
    *   **`telegraph_publisher.py`**: Публикует сгенерированную статью на платформе **Telegra.ph**.
    *   **`telegram_notifier.py`**: Отправляет уведомление со ссылкой на статью в заданный Telegram-чат.

3.  **Вспомогательные модули:**
    *   **`config.py`**: Управляет загрузкой конфигурации из `.env` файлов.
    *   **`check_session.py`**: Скрипт для проверки валидности сессии Telethon.

## Установка и запуск

### 1. Клонируйте репозиторий
```bash
git clone <your-repo-url>
cd ai_news_digest
```

### 2. Создайте и активируйте виртуальное окружение
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Установите зависимости
```bash
pip install -r requirements.txt
```

### 4. Настройте конфигурацию

Система использует `.env` файлы для конфигурации каждого бота. Вы можете создать несколько таких файлов для запуска разных инстансов.

1.  **Создайте файлы конфигурации.** Например, для AI-бота и HR-бота:
    ```bash
    cp .env.example .env.ai
    cp .env.example .env.hr
    ```

2.  **Заполните переменные** в каждом файле (`.env.ai`, `.env.hr` и т.д.):
    *   `API_ID`, `API_HASH`: Ваши учетные данные из [my.telegram.org](https://my.telegram.org).
    *   `BOT_TOKEN`: Токен Telegram-бота от [@BotFather](https://t.me/BotFather).
    *   `CHAT_ID`: ID целевого Telegram-канала или чата (например, `@my_channel`).
    *   `OPENAI_API_KEY`: Ваш ключ от OpenAI.
    *   `TELEGRAM_CHANNELS`: Список каналов для парсинга, через запятую (например, `channel1,channel2`).
    *   `DB_NAME`: Имя файла для базы данных SQLite (например, `ai_news.db`). **Должно быть уникальным для каждого бота.**
    *   `SUMMARY_PROMPT`: **(Новое)** Системный промпт для первого этапа обработки. Его задача — отфильтровать посты, отобрав самые важные и вернув их в исходном виде.
    *   `ARTICLE_PROMPT`: Основной системный промпт для второго этапа. Его задача — на основе отфильтрованных постов сгенерировать финальную статью и анонс.
    *   `SCHEDULE_DAY_OF_WEEK`: День недели для запуска (например, `mon`, `tue`, `wed`, `thu`, `fri`, `sat`, `sun`).
    *   `SCHEDULE_HOUR`: Час запуска (0-23).
    *   `SCHEDULE_MINUTE`: Минута запуска (0-59).
    *   `TELEGRAM_PARSE_LIMIT`: Количество последних постов, которые нужно проверять в каждом канале.

### 5. Первая авторизация Telethon (создание сессии)

При первом запуске Telethon попросит вас авторизоваться. Это нужно сделать для каждого инстанса, который использует новый номер телефона.

*   Запустите скрипт в режиме инициализации, указав нужный конфиг:
    ```bash
    # для AI-бота
    python main.py --config .env.ai --init-session
    ```
*   Введите номер телефона и код из Telegram. Будет создан файл сессии (например, `ai.session` для `.env.ai`).

### 6. Запуск бота

Вы можете запустить любого из настроенных ботов, указав его файл конфигурации.

```bash
# Запустить AI-бота
python main.py --config .env.ai
```

## Развертывание на сервере (Production)

Для обеспечения постоянной работы бота на сервере рекомендуется использовать `systemd`.

### 1. Создание файла службы Systemd

Создайте файл службы для вашего бота, например, `/etc/systemd/system/ai_news_digest_ai.service`.

```ini
[Unit]
Description=AI News Digest Bot (AI config)
After=network.target

[Service]
User=root
WorkingDirectory=/root/ai_news_digest # Абсолютный путь к корневой директории проекта
ExecStart=/root/ai_news_digest/venv/bin/python -u main.py --config .env.ai
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

**Важные моменты:**
*   Замените пути на актуальные для вашей системы.
*   Флаг `-u` у `python` (`python -u main.py`) **крайне важен**. Он отключает буферизацию вывода и гарантирует, что все логи из `print()` будут сразу попадать в `journalctl`.

### 2. Управление службой Systemd

*   **Перезагрузка конфигурации** (после каждого изменения `.service` файла):
    ```bash
    sudo systemctl daemon-reload
    ```
*   **Включение службы** (добавление в автозагрузку):
    ```bash
    sudo systemctl enable ai_news_digest_ai.service
    ```
*   **Запуск/Остановка/Перезапуск:**
    ```bash
    sudo systemctl start ai_news_digest_ai.service
    sudo systemctl stop ai_news_digest_ai.service
    sudo systemctl restart ai_news_digest_ai.service
    ```
*   **Проверка статуса и логов:**
    ```bash
    sudo systemctl status ai_news_digest_ai.service
    sudo journalctl -u ai_news_digest_ai.service -f # Следить за логами в реальном времени
    ```

### 3. Сброс обработанных постов (для отладки)

Если вам нужно заново обработать посты (например, после изменения промпта), вы можете сбросить флаг `is_processed` в базе данных.

1.  **Сбросить все посты:**
    ```bash
    sqlite3 <имя_базы.db> "UPDATE posts SET is_processed = 0 WHERE is_processed = 1;"
    ```
2.  **Сбросить только последнюю "пачку"** (посты за последнюю неделю):
    ```bash
    sqlite3 <имя_базы.db> "UPDATE posts SET is_processed = 0 WHERE is_processed = 1 AND date >= (SELECT MAX(date) - 604800 FROM posts WHERE is_processed = 1);"
    ```

После сброса просто перезапустите сервис `systemd`, чтобы немедленно начать обработку.